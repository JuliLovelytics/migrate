{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevent wide columns from being cut off\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving notebooks we want to keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# /Users/robbfournier/Desktop/E2_Migrations/Elsevier/logs/STexport2/artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = '/Users/robbfournier/Desktop/E2_Migrations/Elsevier/logs/STexport2/artifacts_old'\n",
    "dest_folder = '/Users/robbfournier/Desktop/E2_Migrations/Elsevier/logs/STexport2/artifacts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move artifacts folder to artifacts_old\n",
    "# This way the filtered folder is called artifacts and the import tool will use the correct one\n",
    "# source/dest reads backwards for this step but makes sense going forward \n",
    "\n",
    "if not Path(source_folder).is_dir() and Path(dest_folder).is_dir():\n",
    "    shutil.move(dest_folder, source_folder)\n",
    "else:\n",
    "    raise Exception('Make sure to have notebooks in a folder called artifacts and delete the folder artifacts_old if it already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in notebooks to keep and rename 'notebook' column to 'source' for disambiguation\n",
    "df = pd.read_csv('keep_notebooks.csv', delimiter='\\t')\n",
    "df.rename(columns={'notebook':'source'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe where source and dest are Path objects instead of strings\n",
    "# Append '.dbc' to each filename\n",
    "\n",
    "keep_df = pd.DataFrame()\n",
    "keep_df['source'] = df['source'].apply(lambda x: Path(source_folder + x + '.dbc'))\n",
    "keep_df['dest'] = df['source'].apply(lambda x: Path(dest_folder + x + '.dbc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/Users/robbfournier/Desktop/E2_Migrations/Elsevier/logs/STexport2/artifacts_old/Users/d.mcbeath@elsevier.com/E2Migration/Migrate/Groups.dbc'\n",
      "[Errno 2] No such file or directory: '/Users/robbfournier/Desktop/E2_Migrations/Elsevier/logs/STexport2/artifacts_old/Users/d.mcbeath@elsevier.com/TERMite/Concordancer.dbc'\n",
      "[Errno 2] No such file or directory: '/Users/robbfournier/Desktop/E2_Migrations/Elsevier/logs/STexport2/artifacts_old/rads/projects/2022_AUS_ARC/PlumX/Match_with_PlumX_Data.dbc'\n",
      "[Errno 2] No such file or directory: '/Users/robbfournier/Desktop/E2_Migrations/Elsevier/logs/STexport2/artifacts_old/rads/projects/2022_AUS_ARC/TRO analysis/stats_paul.dbc'\n",
      "[Errno 2] No such file or directory: '/Users/robbfournier/Desktop/E2_Migrations/Elsevier/logs/STexport2/artifacts_old/rads/projects/2022_AUS_ARC/Preliminary report (30 Sept. 2022)/ARC_Indexing_30sept.dbc'\n",
      "[Errno 2] No such file or directory: '/Users/robbfournier/Desktop/E2_Migrations/Elsevier/logs/STexport2/artifacts_old/rads/projects/2022_AUS_ARC/TRO analysis/stats_luigi_with_citations.dbc'\n",
      "[Errno 2] No such file or directory: '/Users/robbfournier/Desktop/E2_Migrations/Elsevier/logs/STexport2/artifacts_old/rads/projects/2022_AUS_ARC/TRO analysis/stats_luigi.dbc'\n",
      "[Errno 2] No such file or directory: '/Users/robbfournier/Desktop/E2_Migrations/Elsevier/logs/STexport2/artifacts_old/Shared/ResearchMetrics/Epics/No-Epic/Twitter CM Notebook.dbc'\n",
      "[Errno 2] No such file or directory: '/Users/robbfournier/Desktop/E2_Migrations/Elsevier/logs/STexport2/artifacts_old/rads/projects/2022_AUS_ARC/TRO analysis/QA on TRO matched and unmatched.dbc'\n",
      "[Errno 2] No such file or directory: '/Users/robbfournier/Desktop/E2_Migrations/Elsevier/logs/STexport2/artifacts_old/rads/projects/2022_AUS_ARC/Preliminary report (30 Sept. 2022)/30sept_mainTables.dbc'\n",
      "[Errno 2] No such file or directory: '/Users/robbfournier/Desktop/E2_Migrations/Elsevier/logs/STexport2/artifacts_old/rads/projects/2022_AUS_ARC/Preliminary report (30 Sept. 2022)/ARC_ERA2018_matching.dbc'\n",
      "[Errno 2] No such file or directory: '/Users/robbfournier/Desktop/E2_Migrations/Elsevier/logs/STexport2/artifacts_old/rads/projects/2022_AUS_ARC/Preliminary report (30 Sept. 2022)/Q1B_Citation_Linking_Analysis_(Crhis_Rosin).dbc'\n",
      "[Errno 2] No such file or directory: '/Users/robbfournier/Desktop/E2_Migrations/Elsevier/logs/STexport2/artifacts_old/rads/projects/2022_AUS_ARC/TRO analysis/luigi_unmatched_TRO_exploration.dbc'\n",
      "13 files failed to copy\n"
     ]
    }
   ],
   "source": [
    "# Loop through each row and copy the file in location 'source' to the location 'dest'\n",
    "# Creates dest directories if they don't exist\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for _, row in keep_df.iterrows():\n",
    "    row['dest'].parent.mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        shutil.copy(row['source'], row['dest'])\n",
    "    except Exception as e:\n",
    "        counter += 1\n",
    "        print(e)\n",
    "\n",
    "print (f\"{counter} files failed to copy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 notebooks were not copied\n"
     ]
    }
   ],
   "source": [
    "# Checking that all notebooks were copied by making a list of every file with a .dbc file extension in /artifacts/ and all subfolders\n",
    "all_notebooks = Path(dest_folder).glob('**/*.dbc')\n",
    "all_notebooks = [x for x in all_notebooks if x.is_file()]\n",
    "\n",
    "# Compare how many .dbc files are in the dest folder against the number of rows in keep_df\n",
    "if len(all_notebooks) == keep_df.shape[0]:\n",
    "    print('All notebooks copied successfully')\n",
    "else:\n",
    "    print(f'{keep_df.shape[0] - len(all_notebooks)} notebooks were not copied')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archiving Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_folder = \"/Users/robbfournier/Desktop/E2_Migrations/Elsevier/logs/STexport2/artifacts/Archive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in notebooks to archive and rename 'notebook' column to 'source' for disambiguation\n",
    "df = pd.read_csv('archive_notebooks.csv', delimiter='\\t')\n",
    "df.rename(columns={'notebook':'source'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe where source and dest are Path objects instead of strings\n",
    "# Append '.dbc' to each filename\n",
    "\n",
    "archive_df = pd.DataFrame()\n",
    "archive_df['source'] = df['source'].apply(lambda x: Path(source_folder + x + '.dbc'))\n",
    "archive_df['dest'] = df['source'].apply(lambda x: Path(archive_folder + x + '.dbc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 files failed to copy\n"
     ]
    }
   ],
   "source": [
    "# Loop through each row and copy the file in location 'source' to the location 'dest'\n",
    "# Creates destination directories if they don't exist\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for _, row in archive_df.iterrows():\n",
    "    row['dest'].parent.mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        shutil.copy(row['source'], row['dest'])\n",
    "    except Exception as e:\n",
    "        counter += 1\n",
    "        print(e)\n",
    "\n",
    "print (f\"{counter} files failed to copy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All archived notebooks copied successfully\n"
     ]
    }
   ],
   "source": [
    "# Checking that all notebooks were copied by making a list of every file with a .dbc file extension in /artifacts/archive/ and all subfolders\n",
    "all_archived_notebooks = Path(archive_folder).glob('**/*.dbc')\n",
    "all_archived_notebooks = [x for x in all_archived_notebooks if x.is_file()]\n",
    "\n",
    "# Compare how many .dbc files are in the archive folder against the number of rows in archive_df\n",
    "if len(all_archived_notebooks) == archive_df.shape[0]:\n",
    "    print('All archived notebooks copied successfully')\n",
    "else:\n",
    "    print(f'{archive_df.shape[0] - len(all_archived_notebooks)} notebooks were not copied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
